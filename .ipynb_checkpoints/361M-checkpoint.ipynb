{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished reading train.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "data = pd.read_csv('train.csv', header=None, skiprows=1, parse_dates=[0,11,12])\n",
    "print(\"finished reading train.csv\")\n",
    "data.columns = [\"date_time\", \"site_name\", \"posa_continent\", \"user_location_country\",\n",
    "                \"user_location_region\", \"user_location_city\", \"orig_destination_distance\",\n",
    "                \"user_id\", \"is_mobile\", \"is_package\", \"channel\", \"srch_ci\", \"srch_co\",\n",
    "                \"srch_adults_cnt\", \"srch_children_cnt\", \"srch_rm_cnt\", \"srch_destination_id\",\n",
    "                \"srch_destination_type_id\", \"is_booking\", \"cnt\", \"hotel_continent\", \"hotel_country\",\n",
    "                \"hotel_market\", \"hotel_cluster\"] \n",
    "data.drop(data.index[[406250,1373714,1373715,2374706,3504146,3707429,7780825,778086,8040327,8428261,8428262,\n",
    "                     15336804,16428469,16695744,17669511,18156670,18575457,31775817,31784369,32146102,32168215,32549132,\n",
    "                     34815966,34815968,34815969,35412891,36606126,36833435,36833436,37330211]], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data loaded\n",
      "test data loaded\n",
      "pp part 1 complete\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Nov 16 21:32:03 2016\n",
    "\n",
    "@author: Michael\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\"from ml_metrics import average_precision\"\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "print(\"training data loaded\")\n",
    "#dest = pd.read_csv('destinations_mod.csv')\n",
    "#print(\"dest data loaded\")\n",
    "test = pd.read_csv('test.csv', parse_dates=['date_time', 'srch_co'])\n",
    "print(\"test data loaded\")\n",
    "test = test.drop('id', 1)\n",
    "   \n",
    "data = data.drop('cnt', 1)\n",
    "data = data.drop('is_booking', 1)\n",
    "data = data.drop('site_name', 1)\n",
    "data = data.drop('posa_continent', 1)\n",
    "data = data.drop('is_mobile', 1)\n",
    "data = data.drop('is_package', 1)\n",
    "data = data.drop('srch_adults_cnt', 1)\n",
    "data = data.drop('srch_children_cnt', 1)\n",
    "data = data.drop('srch_rm_cnt', 1)\n",
    "data = data.drop('srch_destination_type_id', 1)\n",
    "data = data.drop('hotel_continent', 1)\n",
    "data_y = data[\"hotel_cluster\"]\n",
    "data = data.drop('hotel_cluster', 1)\n",
    "data['srch_ci'] = pd.to_datetime(data['srch_ci'], errors='coerce')\n",
    "data['srch_ci'].fillna(value=pd.to_datetime('7/1/2014'), inplace=True)\n",
    "data['srch_co'] = pd.to_datetime(data['srch_co'], errors='coerce')\n",
    "data['srch_co'].fillna(value=pd.to_datetime('7/4/2014'), inplace=True)\n",
    "data['orig_destination_distance'].fillna(1969, inplace=True)\n",
    "test = test.drop('site_name', 1)\n",
    "test = test.drop('posa_continent', 1)\n",
    "test = test.drop('is_mobile', 1)\n",
    "test = test.drop('is_package', 1)\n",
    "test = test.drop('srch_adults_cnt', 1)\n",
    "test = test.drop('srch_children_cnt', 1)\n",
    "test = test.drop('srch_rm_cnt', 1)\n",
    "test = test.drop('srch_destination_type_id', 1)\n",
    "test = test.drop('hotel_continent', 1)\n",
    "test['srch_ci'].replace(to_replace='nan', value=pd.to_datetime('1/1/2017'), inplace=True)\n",
    "test.set_value(312920, 'srch_ci', pd.to_datetime('1/21/2016'))\n",
    "test['srch_ci'] = pd.to_datetime(test['srch_ci'], errors='coerce')\n",
    "test['srch_co'] = pd.to_datetime(test['srch_co'], errors='coerce')\n",
    "test['srch_ci'].fillna(value=pd.to_datetime('7/1/2015'), inplace=True)\n",
    "test['srch_co'].fillna(value=pd.to_datetime('7/3/2015'), inplace=True)\n",
    "test['orig_destination_distance'].fillna(1685, inplace=True)\n",
    "test_bookings = test.as_matrix(['srch_ci','srch_co'])\n",
    "train_bookings = data.as_matrix(['srch_ci','srch_co'])\n",
    "\n",
    "\n",
    "\n",
    "print(\"pp part 1 complete\")\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "def addStayLengths(matrix_input): #takes in numpy matrices and returns \n",
    "    length_of_stay_values = []\n",
    "    for i in range(0, matrix_input.shape[0]):\n",
    "        m1 = re.search(r'(\\d+-\\d+-\\d+)', str(matrix_input[i][0])) #srch_ci\n",
    "        m2 = re.search(r'(\\d+-\\d+-\\d+)', str(matrix_input[i][1])) #srch_co\n",
    "        match1 = m1.group(0)\n",
    "        values1 = match1.split('-')\n",
    "        year1 = int(values1[0])\n",
    "        month1 = int(values1[1])\n",
    "        day1 = int(values1[2]) \n",
    "\n",
    "        match2 = m2.group(0)\n",
    "        values2 = match2.split('-')         \n",
    "        year2 = int(values2[0])\n",
    "        month2 = int(values2[1])\n",
    "        day2 = int(values2[2])     \n",
    "    #try:\n",
    "        d0 = date(year1, month1, day1)\n",
    "        d1 = date(year2, month2, day2)\n",
    "        delta = d1 - d0\n",
    "        length_of_stay_values.append(delta.days)\n",
    "    #except:\n",
    "    #    print(\"exception: \" + str(matrix_input[i][0]) + \", \" + str(matrix_input[i][1]))\n",
    "    #    length_of_stay_values.append(3)\n",
    "    return length_of_stay_values\n",
    "traincolumn = addStayLengths(train_bookings)\n",
    "testcolumn = addStayLengths(test_bookings)\n",
    "data = data.assign(length_of_stay = traincolumn)\n",
    "test = test.assign(length_of_stay = testcolumn)\n",
    "print(\"length of stay values appended\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addFeatures(df_input):\n",
    "    df_input['date_time_month'] = df_input['date_time'].dt.month\n",
    "    df_input['date_time_day'] = df_input['date_time'].dt.day\n",
    "    df_input['date_time_hour'] = df_input['date_time'].dt.hour\n",
    "    df_input['srch_ci_month'] = df_input['srch_ci'].dt.month\n",
    "    df_input['srch_ci_dayofweek'] = df_input['srch_ci'].dt.dayofweek\n",
    "    df_input['srch_ci_day'] = df_input['srch_ci'].dt.day\n",
    "    #df_input['srch_co_month'] = df_input['srch_co'].dt.month\n",
    "    print(\"new features added\")\n",
    "    df_input = df_input.drop('date_time', 1)\n",
    "    df_input = df_input.drop('srch_ci', 1)\n",
    "    df_input = df_input.drop('srch_co', 1)\n",
    "    #df_input = pd.merge(df_input, dest, on='srch_destination_id', how='left')\n",
    "    df_input.fillna(-2.18, inplace=True)\n",
    "    #df_input = df_input.drop('srch_destination_id', 1)\n",
    "    print(\"pp part 2 complete\")\n",
    "    return df_input\n",
    "    \n",
    "data = addFeatures(data)\n",
    "test = addFeatures(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(data.values, data_y.values)\n",
    "probs = clf.predict_proba(test.values)\n",
    "\n",
    "pred = [];\n",
    "indices = [];\n",
    "for i in range(len(test)):\n",
    "    pred.append(\" \".join(map(str, list(reversed(probs[i].argsort()[-5:])))))\n",
    "    indices.append(i)  \n",
    "\n",
    "df = pd.DataFrame({\"id\" : indices, \"hotel_cluster\" : pred})\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]\n",
    "df.to_csv(\"result_12_6_16_RF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decisionTree = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=20, \n",
    "                                       min_samples_split=2, min_samples_leaf=1, \n",
    "                                       min_weight_fraction_leaf=0.0, max_features=None, \n",
    "                                       random_state=None, max_leaf_nodes=None, \n",
    "                                       min_impurity_split=1e-07, class_weight=None, presort=False)\n",
    "\n",
    "decisionTree.fit(data, data_y)\n",
    "probs = decisionTree.predict_proba(test)\n",
    "pred = [];\n",
    "indices = [];\n",
    "for i in range(len(test)):\n",
    "    pred.append(\" \".join(map(str, list(reversed(probs[i].argsort()[-5:])))))\n",
    "    indices.append(i)  \n",
    "\n",
    "df = pd.DataFrame({\"id\" : indices, \"hotel_cluster\" : pred})\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]\n",
    "df.to_csv(\"result_12_6_16_df_no_co.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decisionTree = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=20, \n",
    "                                       min_samples_split=2, min_samples_leaf=1, \n",
    "                                       min_weight_fraction_leaf=0.0, max_features=None, \n",
    "                                       random_state=None, max_leaf_nodes=None, \n",
    "                                       min_impurity_split=1e-07, class_weight=None, presort=False)\n",
    "\n",
    "decisionTree.fit(data.values, data_y.values)\n",
    "probs = decisionTree.predict_proba(test.values)\n",
    "pred = [];\n",
    "indices = [];\n",
    "for i in range(len(test.values)):\n",
    "    pred.append(\" \".join(map(str, list(reversed(probs[i].argsort()[-5:])))))\n",
    "    indices.append(i)  \n",
    "\n",
    "df = pd.DataFrame({\"id\" : indices, \"hotel_cluster\" : pred})\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]\n",
    "df.to_csv(\"result_12_6_16_np_no_co.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'train_book_indices' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-451cc8758f10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;31m#datai = pd.read_csv('train.csv', header=None, skiprows=1, parse_dates=[0,11,12])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_book_indices'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\jk34678\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\jk34678\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\jk34678\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\jk34678\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\jk34678\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:3427)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas\\parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:6861)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: File b'train_book_indices' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#datai = pd.read_csv('train.csv', header=None, skiprows=1, parse_dates=[0,11,12])\n",
    "indices = pd.read_csv('train_book_indices')\n",
    "indices.head(n=10)\n",
    "indices.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
